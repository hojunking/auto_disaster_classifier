{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'inception_resnet_v2',\n",
    "    'img_size': 260,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':32,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 3,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': True,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed30653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =timm.create_model(CFG['model'], pretrained=True, num_classes=2)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, train_arg=False, sub_path=None):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    if train_arg:\n",
    "        dimg = cv2.fastNlMeansDenoisingColored(im_rgb, None, 10,10,7,21)\n",
    "        return dimg\n",
    "    else:\n",
    "        return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonDataset(Dataset):\n",
    "    def __init__(self, df, data_root, train_arg=False,\n",
    "                 transform=None,\n",
    "                 output_label=True\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.train_arg = train_arg\n",
    "        self.transform = transform\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "        \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root[index], self.df.loc[index]['image_id']), train_arg=self.train_arg)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "        \n",
    "                \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325e04c-e7a8-4f14-bc63-37362013a5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForcepImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        # n_features = self.model.classifier.in_features\n",
    "        # self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def freezing(self, freeze=False, trainable_layer = 2):\n",
    "        \n",
    "        if freeze:\n",
    "            num_layers = len(list(model.parameters()))\n",
    "            for i, param in enumerate(model.parameters()):\n",
    "                if i < num_layers - trainable_layer*2:\n",
    "                    param.requires_grad = False    \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240e5531",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_dataloader\u001b[39m(df, trn_idx, val_idx, data_root\u001b[39m=\u001b[39mtrain\u001b[39m.\u001b[39mdir\u001b[39m.\u001b[39mvalues):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcatalyst\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msampler\u001b[39;00m \u001b[39mimport\u001b[39;00m BalanceClassSampler\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     train_ \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[trn_idx,:]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = ColonDataset(train_,\n",
    "                            train_data_root,\n",
    "                            transform=transform_train,\n",
    "                            output_label=True)\n",
    "    valid_ds = ColonDataset(valid_,\n",
    "                            valid_data_root,\n",
    "                            transform=transform_train,\n",
    "                            output_label=True)\n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        sampler=DistributedSampler(train_ds)\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014d065-a6ad-45f9-aee8-d1adb9da52b4",
   "metadata": {},
   "source": [
    "##### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d62956-1ab7-4c53-ad80-05955c3367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18acac-bdc4-476d-91c3-50fd46b4f1db",
   "metadata": {},
   "source": [
    "##### valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed3ba1-8c45-4e70-b80a-5a26d11cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "                #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "                # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "                torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b952e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab9299-b98a-43ef-ad42-51e4aad3ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
