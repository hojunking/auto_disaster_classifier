{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage import zoom\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 42,\n",
    "    'model': 'inception_resnet_v2',\n",
    "    'img_size': 256,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 10,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 10,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e02c8f5",
   "metadata": {},
   "source": [
    "#### Train dataset\n",
    "##### coco: 894 // flickr: 184 // open_image: 616 // aug 6620 // generated 1782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1beafb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: disaster 10057\n",
      "label: non_disaster 60000\n",
      "Train_Images:  70057\n",
      "Train_Images_labels: 70057\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../Data/disaster/train/\"\n",
    "label_list = [\"disaster\",\"non_disaster\"]\n",
    "\n",
    "train_img_paths = []\n",
    "train_img_labels = []\n",
    "\n",
    "for label in label_list: ## 각 레이블 돌기\n",
    "    print(f'label: {label}',end=' ')\n",
    "    img_paths = [] \n",
    "    img_labels = []\n",
    "    dir_path = train_path + label ## 레이블 폴더 경로\n",
    "\n",
    "    for folder, subfolders, filenames in os.walk(dir_path): ## 폴더 내 모든 파일 탐색\n",
    "        for img in filenames: ## 각 파일 경로, 레이블 저장\n",
    "            img_paths.append(folder+'/'+img)\n",
    "            img_labels.append(label)\n",
    "    \n",
    "    print(len(img_paths))\n",
    "\n",
    "    train_img_paths.extend(img_paths)\n",
    "    train_img_labels.extend(img_labels)\n",
    "\n",
    "print('Train_Images: ',len(train_img_paths))\n",
    "print(\"Train_Images_labels:\", len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69214edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this image there are so many trees on the m...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the center of the image there is a tree. At...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this picture I see a van in front which is ...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this picture we can see a person standing h...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this image there is a person carrying a bag...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70052</th>\n",
       "      <td>0599144da6c18a15.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70053</th>\n",
       "      <td>0eeff61eee2ce4bf.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70054</th>\n",
       "      <td>0578a94b2f1b28de.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70055</th>\n",
       "      <td>075d26862f3320db.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70056</th>\n",
       "      <td>0896299d4884d86f.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image_id  \\\n",
       "0      In this image there are so many trees on the m...   \n",
       "1      In the center of the image there is a tree. At...   \n",
       "2      In this picture I see a van in front which is ...   \n",
       "3      In this picture we can see a person standing h...   \n",
       "4      In this image there is a person carrying a bag...   \n",
       "...                                                  ...   \n",
       "70052                               0599144da6c18a15.jpg   \n",
       "70053                               0eeff61eee2ce4bf.jpg   \n",
       "70054                               0578a94b2f1b28de.jpg   \n",
       "70055                               075d26862f3320db.jpg   \n",
       "70056                               0896299d4884d86f.jpg   \n",
       "\n",
       "                                                     dir         label  \n",
       "0      ../Data/disaster/train/disaster/generated1/ope...      disaster  \n",
       "1      ../Data/disaster/train/disaster/generated1/ope...      disaster  \n",
       "2      ../Data/disaster/train/disaster/generated1/ope...      disaster  \n",
       "3      ../Data/disaster/train/disaster/generated1/ope...      disaster  \n",
       "4      ../Data/disaster/train/disaster/generated1/ope...      disaster  \n",
       "...                                                  ...           ...  \n",
       "70052    ../Data/disaster/train/non_disaster/open_images  non_disaster  \n",
       "70053    ../Data/disaster/train/non_disaster/open_images  non_disaster  \n",
       "70054    ../Data/disaster/train/non_disaster/open_images  non_disaster  \n",
       "70055    ../Data/disaster/train/non_disaster/open_images  non_disaster  \n",
       "70056    ../Data/disaster/train/non_disaster/open_images  non_disaster  \n",
       "\n",
       "[70057 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pandas 데이터프레임 만들기\n",
    "trn_df = pd.DataFrame(train_img_paths, columns=['image_id'])\n",
    "trn_df['dir'] = trn_df['image_id'].apply(lambda x: os.path.dirname(x))\n",
    "trn_df['image_id'] = trn_df['image_id'].apply(lambda x: os.path.basename(x))\n",
    "trn_df['label'] = train_img_labels\n",
    "train = trn_df\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8edec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this image there are so many trees on the m...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the center of the image there is a tree. At...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this picture I see a van in front which is ...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this picture we can see a person standing h...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this image there is a person carrying a bag...</td>\n",
       "      <td>../Data/disaster/train/disaster/generated1/ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70052</th>\n",
       "      <td>0599144da6c18a15.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70053</th>\n",
       "      <td>0eeff61eee2ce4bf.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70054</th>\n",
       "      <td>0578a94b2f1b28de.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70055</th>\n",
       "      <td>075d26862f3320db.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70056</th>\n",
       "      <td>0896299d4884d86f.jpg</td>\n",
       "      <td>../Data/disaster/train/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image_id  \\\n",
       "0      In this image there are so many trees on the m...   \n",
       "1      In the center of the image there is a tree. At...   \n",
       "2      In this picture I see a van in front which is ...   \n",
       "3      In this picture we can see a person standing h...   \n",
       "4      In this image there is a person carrying a bag...   \n",
       "...                                                  ...   \n",
       "70052                               0599144da6c18a15.jpg   \n",
       "70053                               0eeff61eee2ce4bf.jpg   \n",
       "70054                               0578a94b2f1b28de.jpg   \n",
       "70055                               075d26862f3320db.jpg   \n",
       "70056                               0896299d4884d86f.jpg   \n",
       "\n",
       "                                                     dir  label  \n",
       "0      ../Data/disaster/train/disaster/generated1/ope...      0  \n",
       "1      ../Data/disaster/train/disaster/generated1/ope...      0  \n",
       "2      ../Data/disaster/train/disaster/generated1/ope...      0  \n",
       "3      ../Data/disaster/train/disaster/generated1/ope...      0  \n",
       "4      ../Data/disaster/train/disaster/generated1/ope...      0  \n",
       "...                                                  ...    ...  \n",
       "70052    ../Data/disaster/train/non_disaster/open_images      1  \n",
       "70053    ../Data/disaster/train/non_disaster/open_images      1  \n",
       "70054    ../Data/disaster/train/non_disaster/open_images      1  \n",
       "70055    ../Data/disaster/train/non_disaster/open_images      1  \n",
       "70056    ../Data/disaster/train/non_disaster/open_images      1  \n",
       "\n",
       "[70057 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'].values)\n",
    "#test['label'] = le.transform(test['label'].values)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581a512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'disaster_'+ 'icp_res'\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, sub_path=None):\n",
    "    try:\n",
    "        im_bgr = cv2.imread(path)\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "        past_path = path\n",
    "    except: ## 이미지 에러 발생 시 백지로 대체\n",
    "        #im_bgr = cv2.imread('../Data/carbon_reduction/temp_img.jpg')\n",
    "        im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform=None, output_label=True):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "         \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # GET IMAGES\n",
    "        path = \"{}/{}\".format(self.data_root[index], self.df.iloc[index]['image_id'])\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        # GET LABELS\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img, target\n",
    "        else:\n",
    "            transformed =self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseModel(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        # n_features = self.model.classifier.in_features\n",
    "        # self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    def freezing(self, freeze=False, trainable_layer = 2):\n",
    "        \n",
    "        if freeze:\n",
    "            num_layers = len(list(model.parameters()))\n",
    "            for i, param in enumerate(model.parameters()):\n",
    "                if i < num_layers - trainable_layer*2:\n",
    "                    param.requires_grad = False    \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = CustomDataset(train_, train_data_root, transform=transform_train, output_label=True)\n",
    "    valid_ds = CustomDataset(valid_, valid_data_root, transform=transform_test,  output_label=True)\n",
    "\n",
    "    # WEIGHTEDRANDOMSAMPLER\n",
    "    class_counts = train_.label.value_counts(sort=False).to_dict()\n",
    "    num_samples = sum(class_counts.values())\n",
    "    print(f'cls_cnts: {len(class_counts)}\\nnum_samples:{num_samples}')\n",
    "    \n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "    t_labels = train_.label.to_list()\n",
    "    \n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "\n",
    "    # weight 제작, 전체 학습 데이터 수를 해당 클래스의 데이터 수로 나누어 줌\n",
    "    class_weights = {l:round(num_samples/class_counts[l], 2) for l in class_counts.keys()}\n",
    "\n",
    "    # class 별 weight를 전체 trainset에 대응시켜 sampler에 넣어줌\n",
    "    weights = [class_weights[t_labels[i]] for i in range(int(num_samples))] \n",
    "    sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        sampler=sampler, \n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5014d065-a6ad-45f9-aee8-d1adb9da52b4",
   "metadata": {},
   "source": [
    "##### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d62956-1ab7-4c53-ad80-05955c3367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb18acac-bdc4-476d-91c3-50fd46b4f1db",
   "metadata": {},
   "source": [
    "##### valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ed3ba1-8c45-4e70-b80a-5a26d11cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        # TEACHER MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        print(f' present score: {score}')\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =baseModel(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "                #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "                # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "                torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fa365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojunking\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/git/KD_models/wandb/run-20230520_211812-9df9bu1i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojunking/KD_resnet152_pet/runs/9df9bu1i' target=\"_blank\">youthful-pine-7</a></strong> to <a href='https://wandb.ai/hojunking/KD_resnet152_pet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojunking/KD_resnet152_pet' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_pet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojunking/KD_resnet152_pet/runs/9df9bu1i' target=\"_blank\">https://wandb.ai/hojunking/KD_resnet152_pet/runs/9df9bu1i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet152\n",
      "Training start with fold: 0 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3807: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:07<00:00,  1.03s/it]\n",
      "epoch 0 loss: 0.0149: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:22<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.07135] Val Loss : [0.01455] Val F1 Score : [0.99682]\n",
      " present score: 0.9968199316896865\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.0238: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:05<00:00,  1.01s/it]\n",
      "epoch 1 loss: 0.0174: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.02798] Val Loss : [0.01669] Val F1 Score : [0.99364]\n",
      " present score: 0.9936357442711499\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9968199316896865\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0185: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "epoch 2 loss: 0.0137: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.02566] Val Loss : [0.01313] Val F1 Score : [0.99576]\n",
      " present score: 0.9957571628474333\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9968199316896865\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0164: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 3 loss: 0.0183: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.00764] Val Loss : [0.01755] Val F1 Score : [0.99365]\n",
      " present score: 0.9936521112833723\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9968199316896865\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0120: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 4 loss: 0.0243: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.01341] Val Loss : [0.02327] Val F1 Score : [0.99260]\n",
      " present score: 0.9925988505852297\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9968199316896865\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0043: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:03<00:00,  1.03it/s]\n",
      "epoch 5 loss: 0.0103: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:20<00:00,  1.22s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.00520] Val Loss : [0.00996] Val F1 Score : [0.99682]\n",
      " present score: 0.9968199316896865\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9968199316896865\n",
      "stop called\n",
      "time : 0:08:25\n",
      "fold: 0, Best Epoch : 0/ 6\n",
      "Best Train Marco F1 : 0.97860\n",
      "[[2038   43]\n",
      " [  46 2032]]\n",
      "Best Valid Marco F1 : 0.99682\n",
      "[[677   2]\n",
      " [  1 360]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 1 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4159\n",
      "Fold: 1\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3703: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.10it/s]\n",
      "epoch 0 loss: 0.0105: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:16<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.08417] Val Loss : [0.01003] Val F1 Score : [0.99471]\n",
      " present score: 0.9947134647037355\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0521: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.03it/s]\n",
      "epoch 1 loss: 0.0124: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.02077] Val Loss : [0.01190] Val F1 Score : [0.99366]\n",
      " present score: 0.9936601859678783\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9947134647037355\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0196: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.10it/s]\n",
      "epoch 2 loss: 0.0136: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:17<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.02309] Val Loss : [0.01297] Val F1 Score : [0.99577]\n",
      " present score: 0.9957680741889148\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0123: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:58<00:00,  1.11it/s]\n",
      "epoch 3 loss: 0.0080: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.01981] Val Loss : [0.00763] Val F1 Score : [0.99576]\n",
      " present score: 0.9957626428070862\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9957680741889148\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0073: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 4 loss: 0.0100: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:16<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.01326] Val Loss : [0.00961] Val F1 Score : [0.99576]\n",
      " present score: 0.9957626428070862\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9957680741889148\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0119: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:00<00:00,  1.07it/s]\n",
      "epoch 5 loss: 0.0050: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.00966] Val Loss : [0.00480] Val F1 Score : [0.99788]\n",
      " present score: 0.9978813214035431\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.0048: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 6 loss: 0.0052: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:16<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.00520] Val Loss : [0.00496] Val F1 Score : [0.99788]\n",
      " present score: 0.9978813214035431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9978813214035431\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0047: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 7 loss: 0.0018: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:17<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.00596] Val Loss : [0.00171] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.0024: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 8 loss: 0.0027: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.00505] Val Loss : [0.00259] Val F1 Score : [0.99788]\n",
      " present score: 0.9978813214035431\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9 loss: 0.0177: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:58<00:00,  1.10it/s]\n",
      "epoch 9 loss: 0.0011: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.00382] Val Loss : [0.00106] Val F1 Score : [1.00000]\n",
      " present score: 1.0\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 loss: 0.0013: 100%|███████████████████████████████████████████████████████████████████████| 65/65 [01:04<00:00,  1.01it/s]\n",
      "epoch 10 loss: 0.0010: 100%|███████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.00189] Val Loss : [0.00100] Val F1 Score : [1.00000]\n",
      " present score: 1.0\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 1.0\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11 loss: 0.0008: 100%|███████████████████████████████████████████████████████████████████████| 65/65 [01:00<00:00,  1.08it/s]\n",
      "epoch 11 loss: 0.0041: 100%|███████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.00126] Val Loss : [0.00394] Val F1 Score : [0.99788]\n",
      " present score: 0.9978813214035431\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 1.0\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12 loss: 0.0018: 100%|███████████████████████████████████████████████████████████████████████| 65/65 [01:00<00:00,  1.08it/s]\n",
      "epoch 12 loss: 0.0017: 100%|███████████████████████████████████████████████████████████████████████| 17/17 [00:20<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.00115] Val Loss : [0.00159] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 1.0\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13 loss: 0.0008: 100%|███████████████████████████████████████████████████████████████████████| 65/65 [01:03<00:00,  1.02it/s]\n",
      "epoch 13 loss: 0.0026: 100%|███████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.00086] Val Loss : [0.00251] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 1.0\n",
      "Epoch 14/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 14 loss: 0.0017: 100%|███████████████████████████████████████████████████████████████████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "epoch 14 loss: 0.0031: 100%|███████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.00409] Val Loss : [0.00297] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 1.0\n",
      "stop called\n",
      "time : 0:20:06\n",
      "fold: 1, Best Epoch : 9/ 15\n",
      "Best Train Marco F1 : 0.99856\n",
      "[[2110    3]\n",
      " [   3 2043]]\n",
      "Best Valid Marco F1 : 1.00000\n",
      "[[679   0]\n",
      " [  0 361]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 2 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4159\n",
      "Fold: 2\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.3792: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:04<00:00,  1.00it/s]\n",
      "epoch 0 loss: 0.0396: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:21<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.07195] Val Loss : [0.03790] Val F1 Score : [0.99047]\n",
      " present score: 0.9904720702379437\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0202: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 1 loss: 0.0180: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.02743] Val Loss : [0.01717] Val F1 Score : [0.99682]\n",
      " present score: 0.9968158034126016\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0204: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:58<00:00,  1.11it/s]\n",
      "epoch 2 loss: 0.0234: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.01371] Val Loss : [0.02235] Val F1 Score : [0.99788]\n",
      " present score: 0.9978813214035431\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0070: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:00<00:00,  1.08it/s]\n",
      "epoch 3 loss: 0.0250: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.01144] Val Loss : [0.02393] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0094: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 4 loss: 0.0602: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:20<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.01605] Val Loss : [0.05761] Val F1 Score : [0.99261]\n",
      " present score: 0.9926082290311804\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0045: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "epoch 5 loss: 0.0283: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.00694] Val Loss : [0.02709] Val F1 Score : [0.99682]\n",
      " present score: 0.996824023412648\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0023: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:57<00:00,  1.12it/s]\n",
      "epoch 6 loss: 0.0234: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.00323] Val Loss : [0.02237] Val F1 Score : [0.99788]\n",
      " present score: 0.9978785814237167\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0009: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.05it/s]\n",
      "epoch 7 loss: 0.0308: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.00184] Val Loss : [0.02946] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0012: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:00<00:00,  1.07it/s]\n",
      "epoch 8 loss: 0.0249: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hojun/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.00055] Val Loss : [0.02380] Val F1 Score : [0.99894]\n",
      " present score: 0.9989399772298955\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Best F1 score from now: 0.9989399772298955\n",
      "stop called\n",
      "time : 0:12:06\n",
      "fold: 2, Best Epoch : 3/ 9\n",
      "Best Train Marco F1 : 0.99615\n",
      "[[2087    8]\n",
      " [   8 2056]]\n",
      "Best Valid Marco F1 : 0.99894\n",
      "[[678   1]\n",
      " [  0 361]]\n",
      "-----------------------------------------------------------------------\n",
      "Training start with fold: 3 epoch: 200 \n",
      "\n",
      "cls_cnts: 2\n",
      "num_samples:4159\n",
      "Fold: 3\n",
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4197: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "epoch 0 loss: 0.0173: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.07659] Val Loss : [0.01695] Val F1 Score : [0.99254]\n",
      " present score: 0.9925407925407925\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 loss: 0.0614: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "epoch 1 loss: 0.0066: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.03016] Val Loss : [0.00868] Val F1 Score : [0.99469]\n",
      " present score: 0.994693005687669\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2 loss: 0.0115: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 2 loss: 0.0120: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.01660] Val Loss : [0.01152] Val F1 Score : [0.99361]\n",
      " present score: 0.9936106423761858\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.994693005687669\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3 loss: 0.0120: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 3 loss: 0.0123: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.01897] Val Loss : [0.01348] Val F1 Score : [0.99681]\n",
      " present score: 0.9968116383375965\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4 loss: 0.0150: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:59<00:00,  1.09it/s]\n",
      "epoch 4 loss: 0.0043: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.01587] Val Loss : [0.00448] Val F1 Score : [0.99788]\n",
      " present score: 0.9978758169934641\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5 loss: 0.0063: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:07<00:00,  1.04s/it]\n",
      "epoch 5 loss: 0.0046: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:19<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.00989] Val Loss : [0.00454] Val F1 Score : [0.99788]\n",
      " present score: 0.9978758169934641\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9978758169934641\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6 loss: 0.0045: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [00:58<00:00,  1.11it/s]\n",
      "epoch 6 loss: 0.0023: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.00434] Val Loss : [0.00232] Val F1 Score : [0.99894]\n",
      " present score: 0.9989372127791988\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7 loss: 0.0022: 100%|████████████████████████████████████████████████████████████████████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "epoch 7 loss: 0.0041: 100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:18<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.00255] Val Loss : [0.00407] Val F1 Score : [0.99894]\n",
      " present score: 0.9989372127791988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best F1 score from now: 0.9989372127791988\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8 loss: 0.0022:  32%|███████████████████████▎                                                | 21/65 [00:25<00:38,  1.15it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        # EARLY STOPPING DEFINITION\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "        # DATALOADER DEFINITION\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        # MODEL & DEVICE DEFINITION \n",
    "        device = torch.device(CFG['device'])\n",
    "        model =Teacher(CFG['model'], train.label.nunique(), pretrained=True)\n",
    "        \n",
    "        # MODEL FREEZING\n",
    "        #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "        if CFG['freezing'] ==True:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "        model.to(device)\n",
    "        # MODEL DATA PARALLEL\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "        # CRITERION (LOSS FUNCTION)\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        \n",
    "\n",
    "        start = time.time()\n",
    "        print(f'Fold: {fold}')\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "            # TRAINIG\n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            # VALIDATION\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "            \n",
    "            # SAVE ALL RESULTS\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "\n",
    "            # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                best_epoch = epoch\n",
    "                # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "                #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "                # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "                torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        # K-FOLD END\n",
    "        if valid_f1_list[best_index] > best_fold:\n",
    "            best_fold = valid_f1_list[best_index]\n",
    "            top_fold = fold\n",
    "    print(f'Best Fold F1 score: {best_fold} Top fold : {top_fold}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
