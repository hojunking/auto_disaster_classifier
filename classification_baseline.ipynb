{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, magic, shutil\n",
    "from glob import glob\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import sklearn\n",
    "#from skimage import io\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n",
    "from catalyst.data.sampler import BalanceClassSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f53a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1' #본인이 사용하고 싶은 GPU 넘버를 써주면 됨\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '43097'         # 좀 큰 숫자로 맞추면 됨 작은 숫자는 에러발생!\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# init!\n",
    "torch.distributed.init_process_group(backend='nccl', init_method=\"env://\", rank =0, world_size=1)  # rank should be 0 ~ world_size-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 0,\n",
    "    'model': 'resnet18',\n",
    "    'img_size': 260,\n",
    "    'epochs': 100,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':64,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'num_workers': 8,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 6,\n",
    "    'device': 'cuda:0',\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed30653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =timm.create_model(CFG['model'], pretrained=True, num_classes=2)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path, train_arg=False, sub_path=None):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    if train_arg:\n",
    "        dimg = cv2.fastNlMeansDenoisingColored(im_rgb, None, 10,10,7,21)\n",
    "        return dimg\n",
    "    else:\n",
    "        return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColonDataset(Dataset):\n",
    "    def __init__(self, df, data_root, train_arg=False,\n",
    "                 transform=None,\n",
    "                 output_label=True\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.train_arg = train_arg\n",
    "        self.transform = transform\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "        \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root[index], self.df.loc[index]['image_id']), train_arg=self.train_arg)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image']\n",
    "        \n",
    "                \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForcepImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        try :\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "        except :\n",
    "            \n",
    "            try : \n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, n_class)\n",
    "            \n",
    "            except :\n",
    "                try:\n",
    "                    n_features = self.model.head.fc.in_channels\n",
    "                    self.model.head.fc = nn.Conv2d(n_features,n_class,kernel_size=(1, 1), stride=(1, 1))\n",
    "            \n",
    "                except:\n",
    "                    n_features = self.model.head.in_features\n",
    "                    self.model.head = nn.Linear(n_features, n_class)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240e5531",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_dataloader\u001b[39m(df, trn_idx, val_idx, data_root\u001b[39m=\u001b[39mtrain\u001b[39m.\u001b[39mdir\u001b[39m.\u001b[39mvalues):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcatalyst\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msampler\u001b[39;00m \u001b[39mimport\u001b[39;00m BalanceClassSampler\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e382e302e36222c2275736572223a22686f6a756e222c22706f7274223a33333039377d/home/hojun/git/efficientnet_pytorch/classification_train_efficientnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     train_ \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[trn_idx,:]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root=train.dir.values):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "    train_data_root = data_root[trn_idx]\n",
    "    valid_data_root = data_root[val_idx]\n",
    "    \n",
    "        \n",
    "    train_ds = ColonDataset(train_,\n",
    "                            train_data_root,\n",
    "                            transform=transform_train,\n",
    "                            output_label=True)\n",
    "    valid_ds = ColonDataset(valid_,\n",
    "                            valid_data_root,\n",
    "                            transform=transform_train,\n",
    "                            output_label=True)\n",
    "    \n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"upsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            #print(image_preds.shape, exam_pred.shape)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                \n",
    "                pbar.set_description(description)\n",
    "            \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, \n",
    "                        image_preds_all, \n",
    "                        average='macro')\n",
    "    \n",
    "    accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    #print('train accuracy = {:.5f}'.format(accuracy))\n",
    "    #print(matrix)\n",
    "    \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "    \n",
    "    return image_preds_all, accuracy, trn_loss, matrix, epoch_f1\n",
    "\n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    acc_list = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]\n",
    "        \n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    matrix = confusion_matrix(image_targets_all,image_preds_all)\n",
    "    \n",
    "    epoch_f1 = f1_score(image_targets_all, \n",
    "                        image_preds_all, \n",
    "                        average='macro')\n",
    "    \n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    #print('validation accuracy = {:.5f}'.format(acc))\n",
    "    #print(matrix)\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "    return image_preds_all, acc, val_loss, matrix, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d9a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "class MyCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '{}'.format(CFG['model'])\n",
    "train_dir = train.dir.values\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    \n",
    "#     wandb.login()\n",
    "#     wandb.init(project=\"3class classification\")\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    \n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "        print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root=train_dir)\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        model = ForcepImgClassifier(CFG['model'], train.label.nunique(), pretrained=True).to(device)\n",
    "\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        model.to(device)\n",
    "        model = DDP(model)\n",
    "\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=25)\n",
    "\n",
    "        loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        wandb.watch(model, loss_tr, log='all')\n",
    "\n",
    "        train_acc_list = []\n",
    "        train_matrix_list = []\n",
    "        train_f1_list = []\n",
    "        valid_acc_list = []\n",
    "        valid_matrix_list = []\n",
    "        valid_f1_list = []\n",
    "        best_f1 =0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print(f'Fold: {fold}')\n",
    "            print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "            \n",
    "            train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                        optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "            wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                        val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "                wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "                \n",
    "            train_acc_list.append(train_acc)\n",
    "            train_matrix_list.append(train_matrix)\n",
    "            train_f1_list.append(train_f1)\n",
    "            \n",
    "            valid_acc_list.append(valid_acc)\n",
    "            valid_matrix_list.append(valid_matrix)\n",
    "            valid_f1_list.append(valid_f1)\n",
    "            \n",
    "            \n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                torch.save(model.state_dict(), (model_dir+'/{}_{}_{}').format(CFG['model'],fold, epoch))\n",
    "                \n",
    "                fig = plt.figure().add_subplot(1, 1, 1)\n",
    "                fig.plot(train_f1_list, label='Train F1')\n",
    "                fig.plot(valid_f1_list, label='Valid F1')\n",
    "                fig.set_title('Train-Valid F1 Score')\n",
    "                fig.legend()\n",
    "                wandb.log({'Train-Valid F1 Score': wandb.Image(fig)})\n",
    "                \n",
    "                \n",
    "\n",
    "            # EARLY STOPPING\n",
    "            stop = early_stopping(valid_f1)\n",
    "            if stop:\n",
    "                print(\"stop called\")   \n",
    "                break\n",
    "    \n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_f1_list)}')\n",
    "        \n",
    "        print(f'fold: {fold}, Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        \n",
    "        print(f'fold: {fold}, Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n",
    "        print('---------------------------------------------------------')\n",
    "  \n",
    "    # distibuted for multi gpu -> model.module.cnn_model.state_dict() / if not -> model.cnn_model.state_dict()\n",
    "    #torch.save(model.module.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "\n",
    "    del model, optimizer, train_loader, val_loader, scaler\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b952e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab9299-b98a-43ef-ad42-51e4aad3ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
